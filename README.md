[![CI](https://github.com/nogibjj/Nruta_Mini_Project_10/actions/workflows/cicd.yml/badge.svg)](https://github.com/nogibjj/Nruta_Mini_Project_10/actions/workflows/cicd.yml)

# IDS 706 Mini Project 10 - PySpark Data Processing

### ğŸ—ï¸ Requirements
- Use PySpark to perform data processing on a large dataset
- Include at least one Spark SQL query and one data transformation

### ğŸ“‚ Project Structure
```
â”œâ”€â”€ .devcontainer
â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ data
â”‚   â””â”€â”€ biopics.csv
â”œâ”€â”€ main.py
â”œâ”€â”€ mylib
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ lib.py
â”œâ”€â”€ pyspark_output.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ test_main.py
```

### ğŸ› ï¸ Setup Instructions
#### 1. Clone the Repository
```
git clone https://github.com/nogibjj/Nruta_Mini_Project_10.git
cd Nruta_Mini_Project_10
```

#### 2. Install Dependencies
```
pip install -r requirements.txt
```

#### 3. Download and set up Apache Spark.
- Download Apache Spark and choose the version compatible with your project.
- Extract the Spark package and set the environment variables if necessary. Refer to the Spark documentation for guidance.

#### 4.	Run the Project:
Refer to the Usage section for running specific scripts or modules.

### ğŸ“Š Dataset Description
The data for this project comes from the biopics.csv dataset provided by FiveThirtyEight.

The dataset has the following features:
- title
- country
- year_release
- box_office
- director
- number_of_subjects
- subject
- type_of_subject
- subject_race
- subject_sex
- lead_actor_actress

### ğŸ—ƒï¸ Spark SQL Query
I constructed the following query to analyze the average release year of the biopics alongside the number of subjects they feature:
``` SELECT * FROM biopics WHERE number_of_subjects = 4 ;```
